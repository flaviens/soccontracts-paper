\para{EDA fuzzing}
VlogHammer~\cite{vloghammer} generates a fixed collection of small modules (mostly combinational logic) by starting from a minimal module and applying simple expansions.
Verismith~\cite{verismith} is a grammar-based synthesizable Verilog generator that produces random but valid Verilog programs with deterministic semantics by using an AST-driven, top-down generation strategy to create code snippets.
TransFuzz~\cite{mirtl} generates abstract netlists of hardware operators and leverages Yosys's backend~\cite{wolf2013yosys} to generate Verilog code.
DeLoSo~\cite{deloso} fuzzes EDA command line options based on test cases generated by VlogHammer, Verismith, and TransFuzz.
% As demonstrated in Section~\ref{sec:motivation:syntax-diversity}, these fuzzers have a limited syntactic coverage, which limits their ability to trigger bugs in EDA software.

\para{Fuzzing using LLMs}
% Recent work replaces fixed grammars with LLMs that act as input generators, mutators, or even white-box planners inside a feedback loop.
Universal autoprompted fuzzers use LLMs to synthesize and mutate well-formed programs across many languages~\cite{fuzz4all}.
Others demonstrate that LLMs can be zero-shot fuzzers that both generate seeds and perform structured mutations, with differential testing as an oracle~\cite{titanfuzz}.
LLMs have also been used in white-box settings to read optimization code and derive constraints for inputs that exercise deep compiler operations~\cite{whitefox}, and to infer grammars and state-progressing messages for protocol fuzzing~\cite{meng2024chatafl}.
Empirical studies of LLM-generated fuzz drivers also highlight fragility and the need for iterative prompting and tool feedback~\cite{zhang2024fuzzdriver}.
In the EDA domain, LLMs have been evaluated for synthesizable RTL generation and verification tasks~\cite{verilog-eval,hdleval}, used to translate specifications into assertions~\cite{assertllm}, and applied to stimuli generation~\cite{verilogreader}.

\para{Compositional test case fuzzing}
Another line of work explores constructing complex test cases by assembling simpler ones. 
Rather than relying solely on random mutations or grammar expansion, these approaches treat inputs as fragments that can be composed to expose deeper execution paths. 
For example, Xu et al.~\cite{xu2025phpfusion} combine dataflow-compatible fragments to uncover subtle interpreter bugs. 
Similar ideas have been applied in compiler fuzzing, where fragments of programs are stitched together to stress optimization passes~\cite{Yang2011Csmith, sun2016goopt, lidbury2015manycore}, and in binary fuzzing, where reusable input components are combined to maintain semantic validity while exploring new states~\cite{lemieux2018fairfuzz, bohme2019fuzzing}. 
Such compositional strategies complement grammar-based and LLM-based fuzzing by enabling the systematic construction of complex, semantically valid test cases.
