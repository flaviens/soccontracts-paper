% \para{Testcase reduction}
% Previous work on EDA fuzzing has introduced techniques to reduce the size of testcases~\cite{mirtl,verismith}.
% In our experience, the testcases generated by \ourname are clear enough to be manually inspected.

% \para{Coverage bound}
% Reaching 100\% of coverage would imply triggering all possible errors and warnings.
% \ourname focuses on translation bugs~\cite{mirtl}, which do not require 100\% coverage.
% Listing~\textcolor{cyan}{XXX} shows a function that is not covered by \ourname but that corresponds to error handling.

% \para{Invalid hardware representations}
% Like previous state-of-the-art EDA software fuzzers~\cite{mirtl,verismith}, \ourname focuses on generating valid hardware representations.
% The rationale is that in mistranslation attacks, the design is supplied to a buggy and to a correct EDA application, which will see two different representations of the design.
% Yet if the design does not comply with the SystemVerilog syntax, then the correct EDA application will reject it.
% More advanced attacks can leverage translation bugs in EDA software if we interpret invalid hardware representations into some valid hardware representation, inconsistently across EDA applications.

% \para{Completeness}
Fuzzing is an intrinsically incomplete process, hence our effort does not guarantee that all bugs are found.
Due to the limitations of most EDA software, \ourname has a weaker support for \texttt{X} and \texttt{Z} values, hence \ourname might miss related bugs,
as well as bugs that might arise from SystemVerilog non-compliance as discussed above.
Furthermore, as \ourname relies on a parser that we made ourselves, we acknowledge that it does not support all of SystemVerilog at the moment.
The most notable missing feature as of the writing of the article is arrays as generating testcases for this object is not trivial,
similarly it does not yet support structs as module inputs.
They are nevertheless planned to be supported in the future.
Furthermore \ourname does not support completely default values for parameters such as complex mathematical expressions
as the parser works with regular expressions matching, and regular expressions are not recursive.
\fls{\textcolor{cyan}{TODO JN: Explain what is missing in the parser.}}

% \para{Probability law}
% The different laws that were selected came progressively into being and that explains the apparent complexity of the model.
% Nevertheless the laws accord themselves together to get a simple inequality for $p$
% which was the sole objective of the model.
% We could also have separated the number of fully supported snippets and then only pick randomly from the partially supported ones,
% but we did not think it would foster many differences in the triggered bugs.
% Indeed if the generated code has poorly supported snippets, then the program is hoping to uncover implementation errors for these particular  features.
% On the other hand, if the generated code is very complex and comprise only fully supported snippets,
% then we are hoping to trigger optimisation bugs from the interactions between these snippets.
% Doing both at the same time seemed only to increase debugging time for the bugs that were triggered.

% \para{Other EDA software targets}
% We have focused on RTL simulators, synthesizers and SystemVerilog front-ends.
% Other EDA software classes exist such as place-and-route tools~\cite{OpenROAD}, but do not accept complex SystemVerilog constructs.

% Instead, they typically accept a synthesizer's netlist as input, or use a synthesiser such as Yosys to generate the netlist.
% It is noteworthy that the code produced by \ourname is not necessarily synthesizable as the provided input snippets have not been selected on this criterion
% but excluding these non-synthesizable snippets from the initial pool would make \ourname generate only synthesizable code,
% if it were to be used to fuzz other EDA software such as place-and-route tools.

% \para{Future-proofness}
% \fls{\textcolor{cyan}{TODO discuss whether this work will be obsolete with GPT-6.}}
% Many of the bugs identified by \ourname were almost accessible in the LLM generated snippets but without being triggerable.
% We believe that as new language models are released the quality of LLM based fuzzing will definitely improve
% but that to get the extra coverage and find as many bugs as possible, methods such as those presented in this article will enable higher quality output.
% Furthermore the LLM based snippets are the basis to create a very complex and rich codebase from simple building blocks,
% at a much lesser cost than asking a multi million parameter model to generate a snippet for each iteration of the fuzzer.
% Indeed once the LLM based snippet generation is done, then the fuzzer runs without any further LLM interaction.
% Lastly we believe that this method can be extended to other types of structured inputs,
% less common programming languages, and domain-specific or proprietary languages in which LLM will probably continue to be limited.


% \begin{mdframed}[backgroundcolor=gray!10]
%     \textbf{Why limit the fuzzer to verilog and not make it language agnostic?}
% \end{mdframed}

% Initially the plan was to make the fuzzer language agnostic once it worked for verilog, but the numerous issues that were met, which are so particular to verilog such as determinism are different language support show the need of having a language specific fuzzer for verilog. Nevertheless it could be interesting to use this method of recreating complex code from simple snippets to enhance the current LLM based fuzzers. Especially if they are performing differential fuzzing between tools.

% \begin{mdframed}[backgroundcolor=gray!10]
%     \textbf{Next steps}
% \end{mdframed}

% At the moment there are still 72 mismatches (a program that has at least one input that triggers a simulation discrepancy) that need to be investigated and classified between unpatched bugs and new bugs. Secondly the parser still does not support a few crucial verilog constructs such as arrays, complex math expressions in parameters, and a few other basic types such as \texttt{wor, wand, trior, tri0, tri1, triand, trior, trireg, uwire, supply0} and \texttt{supply1} which are very rarely used in practice but are part of the verilog specification. Furthermore I would like to explore using unit tests from different verilog projects to be used as snippets, and explore the different verilog benchmarks that are available to see if they can be used as snippets.

% \begin{mdframed}[backgroundcolor=gray!10]
%     \textbf{Can a design defect be considered a bug?}
% \end{mdframed}

% The design defects such as Verilator not supporting X types in values but authorising them in conditionals or CXXRTL not supporting indirect clocks, or the division by zero undetermination can definitely be used as safe picks for writing MiRTL trojans that will last a long time. Arguing that they are not bugs is just a play on the semantics and does not hinder their effectiveness.