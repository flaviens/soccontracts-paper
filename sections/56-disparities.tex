\para{Motivation}
If we uniformly select snippets at random from the entire pool, the resulting hardware designs generated by \ourname are frequently rejected by EDA tools (see Section~\ref{sec:disparities:support-collapse}).
We introduce a scoring system and a resulting probabilistic base snippet selection strategy to explore the design space offered by balancing snippets that are fully supported by all tools with those that are not.

\subsection{Support collapse}\label{sec:disparities:support-collapse}
\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{plots/collapse/collapse_analysis.pdf}
    \caption{Support collapse phenomenon in EDA tools}
    \label{fig:support_collapse}
\end{figure}

When running the first version of \ourname, we observed a phenomenon we call \emph{support collapse}.
It occurs because adding more snippets to a design reduces the number of EDA tools that can support the design.
We measure this phenomenon.

\para{Methodology}
We generated 50 test files, each containing an increasing number of randomly selected snippets from the pool of base snippets.
We calculated the scores of the snippets using our scoring system detailed in \ref{sec:disparities:scoring}.

\para{Results}
The results are shown in Figure~\ref{fig:support_collapse}.
The support collapse phenomenon is very explicit when looking at the graph, after combining just four snippets, fewer than half of the tools still support the generated file.
This is a problem for \ourname as it means that the more snippets we add, the less likely it is that the generated file will be accepted by the EDA software.
This is the problem we address in this section~\ref{sec:disparities}.

\subsection{Scoring}
\label{sec:disparities:scoring}

Triggering uncovered lines requires code not supported by all tools, but such snippets must be injected less frequently to keep the output usable.
We introduce a base snippet scoring function that will influence the probability of selecting them for combinations.

\begin{newdesignprinciple}
    Score base snippets by their acceptability by each fuzzing target and adjust the injection strategy accordingly.
\end{newdesignprinciple}

\para{Snippet scoring method}
To determine which base snippets are supported by which tools, we introduce the following scoring system.
We evaluate all base snippets on all target EDA software and assign a score to each snippet as follows.
For each simulator, the snippet gains 1/30 point if the simulator can compile it, and another 1/30 if the simulation can be run without error.
Additionally, the snippet gains 1/30 point if it can be synthesized without error.
The result is a score between 0 and 1.
Snippets scoring 1 are called \emph{consensual snippets}.
Note that many consensual snippets exert basic functionality and are mostly interesting when combined with other snippets.

\subsection{Analysis}
\label{sec:disparities:analysis}

We determine probability laws for the number of base snippets to combine into one hardware representation as an output of \ourname,
and for which snippets to inject in function of their score.
% 
We provide statistics of the scoring distribution of snippets in Section~\ref{sec:eval:score-distribution}.
%
Our objective is to generate snippets that balance tool acceptance with syntactic diversity, while exploring the trade-offs between snippet diversity and acceptance.

We consider the consensual and the non-consensual snippets in two different pools in which we sample base snippets with different probabilities.
% Injecting a consensual snippet does not affect tool support.
% Nevertheless, to reduce debugging effort, it might be of interest to inject many consensual snippets (yielding large files) or focus on non-consensual ones (yielding complex files).
This probabilistic distribution helps produce a balanced exploration of the design space.

We determine an inequality to satisfy to ensure a minimum level of tool support, detailed in Appendix~\ref{sec:appendix:proof}.

We will show in Section~\ref{sec:eval:disparities-evaluation} that this probabilistic model enabled significant improvement in the quality
of the code generated and in the mismatch results and solved the SystemVerilog support collapse issue that we characterized earlier in this section.
